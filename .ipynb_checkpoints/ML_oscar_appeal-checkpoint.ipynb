{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how-to NB regression:\n",
    "#    https://towardsdatascience.com/negative-binomial-regression-f99031bb25b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В оригинальном экcперименте используется Negative Binomial Regression. Схему работы с ней я взял по ссылке выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_with_topics.csv', dtype={'id': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asmagin/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# setting test and train data\n",
    "\n",
    "features = ['gr_low', 'gr_high', 'kw_low', 'kw_high', 'actors_nomineed', 'directors_nomineed', \n",
    "            'writers_nomineed', 'major', 'indimajor', 'dy_1', 'dy_2', 'dy_3', 'const']\n",
    "\n",
    "mask = np.random.rand(len(df[df['year'] < 2019])) < 0.8\n",
    "\n",
    "df_ = sm.add_constant(df)\n",
    "df_train = df_[df_['year'] < 2019][mask]\n",
    "df_test = df_[df_['year'] < 2019][~mask]\n",
    "\n",
    "y_train = df_train['n_oscars_nom']\n",
    "y_test = df_test['n_oscars_nom']\n",
    "\n",
    "X_train = df_train[features]\n",
    "X_test = df_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:           n_oscars_nom   No. Observations:                 9979\n",
      "Model:                            GLM   Df Residuals:                     9966\n",
      "Model Family:                 Poisson   Df Model:                           12\n",
      "Link Function:                    log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -2329.2\n",
      "Date:                Thu, 23 Jan 2020   Deviance:                       3667.5\n",
      "Time:                        15:38:27   Pearson chi2:                 1.73e+04\n",
      "No. Iterations:                     7   Covariance Type:             nonrobust\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "gr_low                 4.2611      1.626      2.621      0.009       1.075       7.447\n",
      "gr_high                1.7994      0.347      5.191      0.000       1.120       2.479\n",
      "kw_low                 1.2371      0.452      2.736      0.006       0.351       2.123\n",
      "kw_high                1.9017      0.091     20.922      0.000       1.724       2.080\n",
      "actors_nomineed        0.4563      0.076      5.971      0.000       0.307       0.606\n",
      "directors_nomineed     0.3458      0.107      3.235      0.001       0.136       0.555\n",
      "writers_nomineed       0.3338      0.109      3.053      0.002       0.120       0.548\n",
      "major                  1.0824      0.100     10.806      0.000       0.886       1.279\n",
      "indimajor              1.5452      0.104     14.865      0.000       1.341       1.749\n",
      "dy_1                   0.0053      0.002      3.315      0.001       0.002       0.008\n",
      "dy_2                   0.0090      0.001      8.291      0.000       0.007       0.011\n",
      "dy_3                   0.0142      0.003      5.316      0.000       0.009       0.019\n",
      "const                 -6.3569      0.259    -24.523      0.000      -6.865      -5.849\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "poisson_training_results = sm.GLM(y_train, X_train, family=sm.families.Poisson()).fit()\n",
    "print(poisson_training_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['BB_LAMBDA'] = poisson_training_results.mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['AUX_OLS_DEP'] = df_train.apply(lambda x: ((x['n_oscars_nom'] - x['BB_LAMBDA'])**2 - x['n_oscars_nom']) / x['BB_LAMBDA'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ‘-1’ at the end of the expression is patsy syntax for saying: \n",
    "# do not to use an intercept of regression; i.e. just fit a straight line passing \n",
    "# through the origin, as suggested by Messrs Cameron and Trivedi.\n",
    "\n",
    "ols_expr = \"\"\"AUX_OLS_DEP ~ BB_LAMBDA - 1\"\"\"\n",
    "aux_olsr_results = smf.ols(ols_expr, df_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BB_LAMBDA    1.41283\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(aux_olsr_results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BB_LAMBDA    2.221362\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_olsr_results.tvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb2_training_results = sm.GLM(y_train, \n",
    "                              X_train,\n",
    "                              family=sm.families.NegativeBinomial(alpha=aux_olsr_results.params[0])).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:           n_oscars_nom   No. Observations:                 9979\n",
      "Model:                            GLM   Df Residuals:                     9966\n",
      "Model Family:        NegativeBinomial   Df Model:                           12\n",
      "Link Function:                    log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -1926.3\n",
      "Date:                Thu, 23 Jan 2020   Deviance:                       2285.4\n",
      "Time:                        15:38:27   Pearson chi2:                 1.68e+04\n",
      "No. Iterations:                     9   Covariance Type:             nonrobust\n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "gr_low                 6.3300      2.023      3.129      0.002       2.365      10.295\n",
      "gr_high                1.9668      0.518      3.798      0.000       0.952       2.982\n",
      "kw_low                 1.5918      0.572      2.784      0.005       0.471       2.713\n",
      "kw_high                2.8209      0.153     18.380      0.000       2.520       3.122\n",
      "actors_nomineed        0.4588      0.096      4.791      0.000       0.271       0.646\n",
      "directors_nomineed     0.6272      0.148      4.225      0.000       0.336       0.918\n",
      "writers_nomineed       0.3053      0.154      1.979      0.048       0.003       0.608\n",
      "major                  0.9914      0.119      8.358      0.000       0.759       1.224\n",
      "indimajor              1.6174      0.124     13.092      0.000       1.375       1.860\n",
      "dy_1                   0.0047      0.002      2.713      0.007       0.001       0.008\n",
      "dy_2                   0.0094      0.001      7.292      0.000       0.007       0.012\n",
      "dy_3                   0.0146      0.004      3.917      0.000       0.007       0.022\n",
      "const                 -6.9168      0.295    -23.463      0.000      -7.495      -6.339\n",
      "======================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(nb2_training_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['oscar_appeal'] = nb2_training_results.get_prediction(df_[features]).predicted_mean\n",
    "df = df.sort_values('oscar_appeal', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_results = {}\n",
    "for year in range(1990, 2020):\n",
    "    scores = sorted(list(df[df['year'] == year]['oscar_appeal']))\n",
    "    ap_results[year] = {scores[i]:i+1 for i in range(len(scores))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'] = df.apply(lambda row:ap_results[row['year']][row['oscar_appeal']]/len(df[df['year']==row['year']]) * 100, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('predicted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
